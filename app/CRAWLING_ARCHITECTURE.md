# 크롤링 코드 아키텍처 설계 분석

## 현재 상황

현재 프로젝트에서는 FastAPI 백엔드에서 두 가지 주요 기능을 담당하고 있습니다:
1. AI 챗봇 기능 (OpenAI API를 사용한 대화 처리)
2. 공공데이터 API 호출 및 데이터 처리

리팩토링 과정에서 공공데이터 API 호출 관련 코드는 Java Spring Boot 백엔드로 이전하기로 결정되었습니다. 웹 크롤링 관련 코드는 현재 `scripts/` 디렉토리에 위치하고 있으며, 장기적으로는 별도의 Python 크롤링 마이크로서비스로 분리될 예정입니다.

## 아키텍처 설계 선택지

크롤링 관련 코드 배치에 대해 다음 두 가지 선택지가 있습니다:

### 1. FastAPI 백엔드 내에 크롤링 코드 유지 (현재 방식)

#### 장점:
- 단일 코드베이스로 관리가 편리함
- Python 기반 크롤링 라이브러리(BeautifulSoup, requests 등)를 활용하기 용이함
- OpenAI 임베딩 생성 코드와 함께 위치하여 통합 관리 용이

#### 단점:
- 챗봇 기능과 크롤링 기능이 혼재되어 코드베이스 복잡성 증가
- 챗봇 백엔드 서버에 크롤링 작업의 부하가 추가됨
- 독립적인 스케일링이 어려움 (챗봇 트래픽이 많을 때 크롤링 작업이 영향을 받을 수 있음)
- 서로 다른 기능 간 의존성으로 인한 유지보수 어려움

### 2. 별도 Python 백엔드로 크롤링 코드 분리

#### 장점:
- 관심사 분리(Separation of Concerns)에 따른 명확한 아키텍처
- 각 서비스의 독립적 스케일링 가능
- 서비스별 배포 및 업데이트를 독립적으로 진행 가능
- 챗봇 백엔드의 복잡성 감소 및 집중화
- 크롤링 작업을 백그라운드/스케줄 작업으로 더 쉽게 구성 가능

#### 단점:
- 추가 서비스 관리에 따른 운영 부담
- 서비스 간 데이터 동기화 메커니즘 필요
- 인프라 복잡성 증가

### 3. Java Spring Boot 백엔드에 크롤링 코드 통합

#### 장점:
- 공공데이터 API와 관련 데이터를 단일 서버에서 관리
- MongoDB 등 데이터 저장소를 공유하여 일관된 데이터 접근 가능

#### 단점:
- Python 기반 크롤링 코드를 Java로 재작성해야 함 (비용 증가)
- 웹 크롤링 작업은 Python 라이브러리가 더 풍부하고 편리함

## 권장 아키텍처

현재 프로젝트의 목표와 요구사항을 고려할 때, **별도의 Python 데이터 수집 마이크로서비스**로 분리하는 것이 가장 적합할 것으로 보입니다.

### 권장 아키텍처 구조

```
[사용자] <--> [React 프론트엔드] <--> [FastAPI 챗봇 백엔드] <--> [OpenAI API]
                       ^
                       |
                       v
[Python 크롤링 마이크로서비스] <--> [MongoDB] <--> [Java Spring Boot 백엔드] <--> [공공데이터 API들]
```

### 구현 계획

1. 기존 크롤링 스크립트를 별도 파이썬 프로젝트로 이전
   - `scripts/` 디렉토리의 코드를 기반으로 새로운 프로젝트 구성
   - 의존성 관리 및 환경 설정 분리
   - 독립적인 실행 환경 구성

2. 주기적 실행을 위한 스케줄러 추가
   - Celery 또는 APScheduler 도입
   - 크롤링 작업 스케줄링 및 모니터링
   - 실패 시 재시도 메커니즘 구현

3. MongoDB 접근을 위한 별도 유틸리티 모듈 구현
   - 데이터베이스 연결 관리
   - 데이터 동기화 메커니즘
   - 에러 처리 및 로깅

4. 크롤링 상태 모니터링 및 로깅 추가
   - 작업 실행 상태 추적
   - 상세 로그 기록
   - 알림 시스템 연동

5. Java Spring Boot 백엔드와 데이터 동기화 메커니즘 구현
   - MongoDB를 공유 데이터 저장소로 활용
   - 데이터 변경 이벤트 처리
   - 캐시 관리

## 전환 단계

1. 현재 코드를 별도 Python 프로젝트로 이전
   - `scripts/` 디렉토리 코드 이전
   - 의존성 및 환경 설정 분리
   - 독립적인 실행 환경 구성

2. 크롤링 서비스를 독립적으로 실행하는 인프라 구성
   - Docker 컨테이너화
   - Kubernetes 배포 구성
   - 모니터링 시스템 연동

3. 공유 MongoDB 인스턴스 구성
   - 접근 권한 설정
   - 데이터 동기화 메커니즘 구현
   - 백업 및 복구 전략 수립

4. 크롤링 결과 알림 API 추가
   - 작업 완료 알림
   - 에러 발생 시 알림
   - 상태 모니터링 API

5. 크롤링 로직 테스트 및 안정화
   - 단위 테스트 작성
   - 통합 테스트 수행
   - 성능 테스트 및 최적화

## 결론

크롤링 코드는 챗봇 기능과 관심사가 다르므로 별도의 마이크로서비스로 분리하는 것이 장기적으로 더 유연하고 확장 가능한 아키텍처를 제공할 것입니다. 현재는 `scripts/` 디렉토리에서 관리되며, 점진적으로 별도 서비스로 분리될 예정입니다. 